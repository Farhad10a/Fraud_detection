{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# ML Algorithm & Metrics Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Data\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "X = data.drop(['Class','Time'], axis = 1)\n",
    "Y = data[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training & test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.40, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardise features\n",
    "sc = StandardScaler()\n",
    "    \n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "mutual_information = mutual_info_classif(X_train, y_train, n_neighbors=5, copy = True)\n",
    "\n",
    "plt.subplots(1, figsize=(28, 1))\n",
    "sns.heatmap(mutual_information[:, np.newaxis].T, cmap='Blues', cbar=False, linewidths=1, annot=True, annot_kws={\"size\": 12})\n",
    "plt.yticks([], [])\n",
    "plt.gca().set_xticklabels(X.columns, rotation=45, ha='right', fontsize=12)\n",
    "plt.suptitle(\"Variable Importance (mutual_info_classif)\", fontsize=12, y=1.2)\n",
    "plt.gcf().subplots_adjust(wspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot,we see that some variables are more important than others, so We'll select these for our classification\n",
    "\n",
    "selected variables are: V3, V4, V7, V9, V10, V11, V12, V14, V16, V17, V18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific variable selection\n",
    "X_opt = data[['V3','V4','V7','V9','V10','V11','V12','V14','V16','V17','V18']]\n",
    "# split into training & test data\n",
    "Xopt_train, Xopt_test, y_train, y_test = train_test_split(X_opt, Y, test_size=0.40, random_state=0)\n",
    "# standardise input\n",
    "Xopt_train = sc.fit_transform(Xopt_train)\n",
    "Xopt_test = sc.transform(Xopt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    m = model[1]\n",
    "    y_train_pred = cross_val_predict(model[1], Xopt_train, y_train, cv=5)\n",
    "    # cm = confusion_matrix(y_train, y_train_pred)\n",
    "    # print('Confusion matrix: ' + model[0])\n",
    "    # print(cm)\n",
    "    # print()\n",
    "    accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    precision = precision_score(y_train, y_train_pred)\n",
    "    recall = recall_score(y_train, y_train_pred)\n",
    "    f1 = f1_score(y_train, y_train_pred)\n",
    "    print(f'{model[0]} Accuracy: {accuracy}')\n",
    "    print(f'{model[0]} Precision: {precision}')\n",
    "    # print(f'{model[0]} Recall: {recall}')\n",
    "    # print(f'{model[0]} f1 - score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(('Gaussian Naive Bayes', GaussianNB()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(('Random Forest', RandomForestClassifier(n_estimators=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=3, random_state=0, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "rfc.fit(Xopt_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "pred_rfc = rfc.predict(Xopt_test)\n",
    "acc_score = '{:.2%}'.format(accuracy_score(y_test,pred_rfc))\n",
    "pre_score = '{:.2%}'.format(precision_score(y_test,pred_rfc))\n",
    "print(f\"The Accuracy Score for Random Forest Classifier Model is {acc_score} with a Precision Score of {pre_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomized search on hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid={'n_estimators':[1,2,3,4,5],'max_depth':[2,4,6,8,10],'min_samples_leaf': \n",
    "[1,2,4],'max_features':[1,2,3,4,5,6,7,8]}\n",
    "\n",
    "pipeline= Pipeline([\n",
    "   ('clf',RandomForestClassifier(n_estimators=3, random_state=0))\n",
    "])\n",
    "\n",
    "number_models=4\n",
    "random_RandomForest_class=RandomizedSearchCV(\n",
    "estimator=pipeline['clf'],\n",
    "param_distributions=parameter_grid,\n",
    "n_iter=number_models,\n",
    "scoring='accuracy',\n",
    "n_jobs=2,\n",
    "cv=4,\n",
    "refit=True,\n",
    "return_train_score=True)\n",
    "\n",
    "random_RandomForest_class.fit(Xopt_train, y_train)\n",
    "predictions=random_RandomForest_class.predict(Xopt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score_upd = '{:.2%}'.format(accuracy_score(y_test,predictions))\n",
    "print(\"Updated Accuracy Score: \",acc_score_upd);\n",
    "print(\"Best params\",random_RandomForest_class.best_params_)\n",
    "print(\"Best score\",random_RandomForest_class.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
